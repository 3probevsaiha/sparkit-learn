{
 "metadata": {
  "name": "",
  "signature": "sha256:99e2249854460576237ff0330d768402e50135d66043820aa6873a7793aeb843"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<pyspark.context.SparkContext at 0x111115e50>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_classification\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "import numpy as np\n",
      "\n",
      "categories = ['alt.atheism', 'soc.religion.christian',\n",
      "              'comp.graphics', 'sci.med']\n",
      "twenty_train = fetch_20newsgroups(subset='train', categories=categories, \n",
      "                                  shuffle=True, random_state=42)\n",
      "classes = np.unique(twenty_train.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from spylearn.feature_extraction.text import SparkHashingVectorizer, SparkTfidfTransformer\n",
      "from spylearn.naive_bayes import SparkMultinomialNB\n",
      "from spylearn.pipeline import SparkPipeline\n",
      "from spylearn.rdd import block"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_rdd = sc.parallelize(twenty_train.data, 4)\n",
      "y_rdd = sc.parallelize(twenty_train.target, 4)\n",
      "data = X_rdd.zip(y_rdd)\n",
      "print data.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2257\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blocked4 = block(data)\n",
      "print blocked4.cache().count()\n",
      "blocked24 = block(data, 100)\n",
      "print blocked24.cache().count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n",
        "24"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline = SparkPipeline([('vect', SparkHashingVectorizer(non_negative=True)), \n",
      "                          ('clf', SparkMultinomialNB())])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline.fit(blocked24, clf__classes=classes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "SparkPipeline(steps=[('vect', SparkHashingVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "            charset_error=None, decode_error=u'strict',\n",
        "            dtype=<type 'numpy.float64'>, encoding=u'utf-8',\n",
        "            input=u'content', lowercase=True, n_features=1048576,\n",
        "            ngram_range=(1, 1), ...\\w+\\\\b', tokenizer=None)), ('clf', SparkMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "pipeline.predict(blocked24.column(0)).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[array([1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3,\n",
        "        1, 3, 1, 3, 3, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 1, 1, 3, 3,\n",
        "        3, 3, 3, 2, 3, 2, 2, 3, 2, 1, 3, 3, 3, 3, 2, 3, 1, 2, 2, 3, 2, 0, 3,\n",
        "        3, 3, 2, 0, 3, 3, 3, 3, 2, 3, 1, 2, 3, 2, 2, 1, 3, 3, 2, 1, 2, 3, 1,\n",
        "        1, 3, 3, 0, 1, 2, 2, 0]),\n",
        " array([3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 1, 2, 3, 2, 2, 3, 3, 3, 3,\n",
        "        3, 3, 0, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 2, 1, 3, 2, 0, 2, 3, 1, 3, 3,\n",
        "        3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 2, 3, 3, 3, 2, 3, 1, 3, 0, 3, 3, 2, 2,\n",
        "        3, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 2, 3, 0, 3, 2, 3, 3,\n",
        "        3, 3, 3, 2, 1, 3, 3, 3]),\n",
        " array([3, 1, 1, 2, 3, 3, 2, 1, 2, 3, 3, 3, 2, 3, 3, 3, 2, 1, 2, 0, 2, 3, 3,\n",
        "        2, 3, 3, 3, 3, 2, 1, 3, 3, 1, 3, 3, 3, 0, 2, 3, 2, 3, 2, 3, 2, 3, 0,\n",
        "        2, 3, 3, 2, 3, 3, 3, 3, 3, 1, 3, 1, 0, 0, 3, 3, 2, 2, 2, 3, 3, 2, 1,\n",
        "        3, 3, 2, 3, 2, 2, 2, 3, 1, 1, 2, 2, 1, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3,\n",
        "        3, 3, 2, 2, 3, 3, 2, 2]),\n",
        " array([3, 3, 2, 3, 3, 0, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 1, 3, 3, 3, 2, 3, 3,\n",
        "        2, 2, 1, 0, 2, 3, 2, 3, 3, 2, 3, 3, 3, 1, 2, 2, 3, 3, 3, 2, 1, 3, 3,\n",
        "        3, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 1, 3, 2, 3, 3, 1, 2,\n",
        "        3, 3, 3, 1, 2, 3, 3, 2, 3, 2, 1, 1, 3, 2, 1, 1, 3, 3, 3, 0, 1, 3, 2,\n",
        "        3, 3, 1, 3, 3, 3, 3, 1]),\n",
        " array([3, 3, 2, 3, 3, 2, 2, 3, 1, 3, 2, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1,\n",
        "        3, 2, 3, 3, 2, 3, 2, 3, 0, 3, 3, 2, 3, 1, 3, 2, 3, 3, 3, 2, 3, 3, 3,\n",
        "        0, 2, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 3, 2,\n",
        "        3, 3, 3, 2, 3, 0, 3, 3, 3, 0, 1, 3, 3, 2, 2, 3, 3, 1, 1, 0, 3, 3, 3,\n",
        "        1, 3, 3, 1, 3, 1, 3, 3]),\n",
        " array([3, 2, 2, 3, 3, 2, 3, 3, 3, 1, 3, 2, 3, 3, 3, 2, 3, 2, 2, 1, 3, 3, 3,\n",
        "        0, 3, 3, 3, 3, 3, 2, 0, 3, 1, 3, 3, 3, 3, 1, 3, 1, 3, 3, 1, 3, 2, 2,\n",
        "        3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 2, 3, 3, 1, 3, 2, 3, 2]),\n",
        " array([3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 3,\n",
        "        3, 1, 3, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 2, 3, 3, 3, 1,\n",
        "        2, 2, 1, 3, 3, 3, 1, 3, 1, 1, 3, 1, 3, 2, 3, 3, 1, 2, 3, 2, 1, 1, 3,\n",
        "        2, 3, 1, 3, 1, 3, 2, 3, 1, 3, 3, 3, 1, 3, 3, 3, 2, 1, 1, 3, 3, 2, 3,\n",
        "        3, 3, 3, 3, 3, 3, 3, 3]),\n",
        " array([0, 1, 3, 2, 2, 2, 0, 3, 3, 1, 3, 1, 3, 2, 3, 1, 3, 2, 3, 3, 1, 3, 3,\n",
        "        3, 2, 3, 3, 2, 1, 3, 3, 2, 1, 3, 2, 3, 3, 2, 2, 3, 3, 0, 2, 3, 2, 1,\n",
        "        2, 1, 3, 2, 1, 2, 3, 2, 2, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 1, 2,\n",
        "        3, 1, 3, 3, 1, 3, 3, 3, 2, 2, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3,\n",
        "        3, 3, 2, 3, 3, 3, 3, 3]),\n",
        " array([3, 2, 2, 3, 3, 3, 2, 3, 2, 3, 3, 1, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 1,\n",
        "        3, 2, 3, 2, 0, 0, 2, 3, 1, 3, 3, 2, 2, 3, 3, 3, 1, 2, 2, 2, 3, 3, 3,\n",
        "        0, 3, 1, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 2, 2, 3, 3, 2,\n",
        "        3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 2, 3, 1, 1, 3, 3, 3,\n",
        "        3, 3, 1, 3, 3, 3, 2, 3]),\n",
        " array([3, 2, 3, 0, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 1, 0, 2, 2, 2, 2,\n",
        "        3, 2, 2, 2, 2, 2, 1, 1, 2, 0, 1, 2, 3, 1, 3, 1, 2, 3, 3, 1, 3, 2, 3,\n",
        "        3, 1, 3, 1, 3, 2, 1, 3, 1, 3, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3,\n",
        "        1, 1, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 2, 2, 2, 3,\n",
        "        3, 3, 2, 3, 3, 2, 1, 3]),\n",
        " array([1, 3, 3, 1, 3, 3, 3, 3, 3, 0, 1, 1, 3, 0, 3, 1, 3, 3, 3, 2, 3, 1, 3,\n",
        "        1, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3,\n",
        "        2, 3, 3, 2, 2, 3, 3, 2, 3, 1, 3, 1, 1, 3, 3, 3, 1, 1, 3, 2, 1, 2, 3,\n",
        "        3, 3, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 3, 3, 1, 3, 2, 2, 3, 3, 2, 3, 3,\n",
        "        3, 3, 2, 3, 3, 3, 3, 1]),\n",
        " array([3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 1, 3, 3,\n",
        "        1, 3, 3, 2, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2,\n",
        "        2, 3, 3, 3, 1, 3, 3, 2, 1, 3, 3, 2, 3, 1, 2, 2, 3, 3]),\n",
        " array([3, 2, 3, 3, 2, 3, 3, 2, 1, 2, 3, 3, 3, 2, 2, 3, 3, 1, 3, 3, 0, 1, 3,\n",
        "        0, 2, 3, 3, 2, 0, 1, 3, 3, 1, 3, 3, 1, 3, 0, 2, 1, 3, 3, 2, 2, 2, 3,\n",
        "        1, 2, 2, 3, 1, 2, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 1, 2,\n",
        "        3, 3, 1, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3,\n",
        "        1, 1, 1, 2, 2, 3, 3, 3]),\n",
        " array([1, 1, 3, 2, 1, 3, 1, 2, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 1, 2, 1, 3, 1,\n",
        "        3, 3, 2, 3, 2, 3, 3, 2, 2, 1, 3, 3, 1, 2, 3, 3, 3, 3, 3, 2, 3, 2, 1,\n",
        "        2, 3, 3, 1, 3, 1, 2, 3, 3, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 1, 2, 3,\n",
        "        3, 1, 3, 3, 3, 3, 3, 0, 3, 1, 3, 1, 2, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3,\n",
        "        2, 2, 3, 1, 3, 3, 1, 2]),\n",
        " array([1, 0, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 2, 1, 2, 3, 2, 3, 3, 3, 3, 3, 2,\n",
        "        3, 1, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 3, 1, 3, 1, 3, 3, 3,\n",
        "        3, 3, 0, 2, 1, 1, 1, 1, 3, 3, 2, 1, 3, 3, 1, 0, 1, 2, 3, 1, 3, 2, 3,\n",
        "        3, 1, 1, 1, 3, 3, 3, 0, 3, 0, 1, 1, 3, 2, 3, 1, 3, 1, 3, 3, 3, 3, 1,\n",
        "        1, 2, 1, 3, 3, 3, 0, 3]),\n",
        " array([3, 3, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 3, 3, 0, 3, 2, 2, 3, 1, 3, 3, 3,\n",
        "        2, 3, 3, 2, 3, 3, 3, 2, 1, 3, 0, 3, 2, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3,\n",
        "        3, 1, 3, 2, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 2, 3, 1, 1, 3, 1, 3,\n",
        "        3, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 3, 1, 3, 2, 1, 2, 3, 3, 2, 3, 3, 3,\n",
        "        3, 3, 3, 3, 2, 3, 2, 2]),\n",
        " array([3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 3, 0, 3, 3,\n",
        "        3, 1, 2, 3, 3, 2, 1, 2, 1, 1, 0, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3,\n",
        "        2, 1, 3, 3, 2, 2, 3, 1, 3, 3, 1, 3, 2, 0, 1, 3, 1, 3, 2, 3, 0, 3, 3,\n",
        "        2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 2, 1, 2, 3, 0, 2, 3, 3, 2, 2,\n",
        "        2, 3, 3, 2, 3, 3, 3, 3]),\n",
        " array([3, 2, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 0, 3, 1, 3, 1, 3, 3, 1, 3, 0,\n",
        "        3, 3, 3, 2, 0, 1, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3,\n",
        "        1, 0, 2, 2, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 1, 3]),\n",
        " array([3, 2, 3, 3, 3, 1, 2, 2, 3, 3, 1, 1, 1, 3, 3, 3, 3, 2, 3, 2, 2, 3, 3,\n",
        "        3, 3, 3, 3, 2, 3, 3, 3, 0, 3, 3, 3, 1, 0, 3, 1, 3, 3, 3, 3, 1, 3, 3,\n",
        "        3, 0, 3, 2, 3, 1, 2, 2, 2, 3, 3, 3, 3, 3, 1, 0, 3, 3, 1, 3, 3, 1, 1,\n",
        "        2, 3, 3, 2, 2, 3, 3, 2, 3, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3,\n",
        "        3, 3, 3, 2, 2, 3, 1, 3]),\n",
        " array([1, 3, 2, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 2, 3, 3, 2, 3, 3,\n",
        "        0, 3, 1, 3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2,\n",
        "        2, 2, 3, 3, 3, 2, 1, 3, 3, 3, 0, 3, 2, 3, 1, 3, 2, 1, 2, 2, 3, 3, 3,\n",
        "        0, 2, 2, 2, 3, 2, 3, 3, 3, 2, 0, 3, 3, 1, 3, 3, 3, 1, 3, 2, 1, 3, 3,\n",
        "        2, 3, 3, 2, 3, 2, 1, 3]),\n",
        " array([1, 2, 3, 2, 2, 3, 0, 3, 1, 1, 2, 2, 3, 3, 2, 3, 1, 3, 1, 3, 3, 2, 2,\n",
        "        1, 3, 3, 3, 3, 1, 2, 1, 3, 1, 3, 2, 1, 0, 3, 2, 3, 3, 3, 3, 3, 3, 3,\n",
        "        3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3,\n",
        "        3, 3, 3, 2, 3, 3, 3, 2, 2, 1, 3, 1, 3, 3, 2, 2, 2, 3, 3, 1, 3, 3, 3,\n",
        "        3, 1, 3, 3, 2, 3, 2, 3]),\n",
        " array([3, 3, 2, 2, 3, 1, 3, 2, 3, 3, 3, 2, 2, 3, 3, 1, 3, 2, 3, 0, 3, 3, 3,\n",
        "        1, 3, 3, 3, 1, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 1, 3, 3,\n",
        "        3, 1, 2, 3, 3, 3, 3, 1, 3, 2, 3, 1, 3, 2, 3, 1, 0, 2, 3, 2, 3, 1, 3,\n",
        "        3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 2, 3, 2, 3, 2,\n",
        "        2, 2, 3, 1, 2, 3, 3, 2]),\n",
        " array([1, 3, 3, 3, 2, 3, 3, 1, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 2,\n",
        "        2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1,\n",
        "        3, 0, 3, 3, 3, 3, 1, 2, 3, 1, 3, 0, 3, 3, 3, 0, 3, 1, 3, 1, 0, 3, 1,\n",
        "        3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3,\n",
        "        2, 3, 2, 3, 1, 1, 3, 3]),\n",
        " array([1, 3, 2, 3, 3, 0, 2, 2, 1, 1, 2, 3, 1, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3,\n",
        "        2, 3, 3, 2, 2, 2, 3, 3, 3, 1, 3, 3, 3, 0, 3, 3, 3, 3, 2, 3, 3, 1, 3,\n",
        "        2, 3, 2, 2, 3, 2, 2, 3, 3, 3, 1, 3, 3, 2, 1, 3, 3, 3, 2])]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline.transform()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vect = SparkHashingVectorizer()\n",
      "\n",
      "Z = data.mapPartitions(splitrdd)\n",
      "Z = vect.transform(Z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Z.map(lambda x: (len(x),x[0].shape)).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[(2, (1024, 1048576)), (2, (1233, 1048576))]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final = clf.spark_fit(Z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.feature_extraction.text import _document_frequency\n",
      "\n",
      "vect = HashingVectorizer()\n",
      "X = vect.transform(twenty_train.data)\n",
      "df = _document_frequency(X)\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "array([6, 0, 0, ..., 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vect = SparkHashingVectorizer(non_negative=True)\n",
      "trans = SparkTfidfTransformer()\n",
      "clf = SparkMultinomialNB()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "<bound method SparkMultinomialNB.fit of SparkMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "<bound method SparkMultinomialNB.fit of SparkMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)>"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "SparkMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Drdd = vect.transform(block(data, 100))\n",
      "Drdd.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "24"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Drdd.column(0).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "(2257, 1048576)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Drdd.take(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[(<100x1048576 sparse matrix of type '<type 'numpy.float64'>'\n",
        "  \twith 13658 stored elements in Compressed Sparse Row format>,\n",
        "  array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 3, 1, 0, 0, 1, 1, 2, 0, 3, 0, 3, 0, 3,\n",
        "         1, 1, 1, 3, 3, 2, 2, 2, 3, 2, 3, 2, 3, 0, 0, 0, 1, 3, 0, 1, 1, 2, 0,\n",
        "         3, 3, 1, 2, 1, 2, 0, 0, 2, 1, 2, 3, 0, 1, 0, 3, 1, 2, 1, 1, 2, 0, 3,\n",
        "         1, 3, 2, 0, 3, 0, 1, 1, 2, 0, 1, 2, 2, 2, 2, 1, 1, 0, 2, 1, 2, 0, 1,\n",
        "         1, 3, 1, 0, 1, 2, 1, 0])),\n",
        " (<100x1048576 sparse matrix of type '<type 'numpy.float64'>'\n",
        "  \twith 18008 stored elements in Compressed Sparse Row format>,\n",
        "  array([0, 3, 0, 2, 3, 0, 3, 1, 0, 2, 3, 2, 3, 3, 1, 2, 3, 2, 2, 0, 0, 2, 0,\n",
        "         2, 3, 0, 2, 3, 0, 0, 0, 3, 2, 3, 2, 2, 2, 1, 3, 2, 0, 2, 2, 1, 1, 2,\n",
        "         3, 3, 2, 2, 3, 1, 3, 0, 0, 1, 2, 2, 0, 3, 2, 1, 1, 3, 0, 0, 3, 2, 2,\n",
        "         0, 1, 3, 1, 3, 3, 3, 3, 3, 0, 1, 2, 2, 1, 2, 3, 2, 1, 0, 1, 2, 0, 3,\n",
        "         3, 1, 0, 1, 1, 0, 1, 3]))]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = trans.fit(Drdd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf._idf_diag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<1048576x1048576 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 1048576 stored elements (1 diagonals) in DIAgonal format>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M.dtype\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "tr = TfidfTransformer()\n",
      "tr.fit(M).transform(M)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "<564x1048576 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 94579 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf._idf_diag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "<1048576x1048576 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 1048576 stored elements (1 diagonals) in DIAgonal format>"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf.transform(Drdd).take(2)[0][0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "(100, 1048576)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}